# 开背
  kafka的开发人员申明kafka是一个CA系统,原因是kafka设计是运行在一个数据中心,网络分区的问题基本不会发生,但其实kafka提供了一些配置,使得用户可以根据具体的业务需求,
进行不同的配置,使得kafka更重一致性亦或是可用性;
  - 比如下面这种配置,就保证了强一致性————任意写入一条数据,都需要所有节点都复制完毕才会返回ack,这样即使之后leader partition所在节点宕机,仍然可以保证选出了的任意一个节点的数据
    都与原partition数据保持一致,可供消费,保证了数据一致性,但如果节点过多,就会导致一次写入操作的耗时过长,可用性就降低了;
    配置:
    replication.factor = 3
    min.insync.replica = 3
    acks = all

  - 而下面的配置,就更注重保证可用性————任意写入一条数据,当leader partition所在主节点写入了就返回ack,但如果在主节点的数据被同步复制到从节点之前发生了宕机,那么,重新选举之后,
    无论选的是哪个子节点,都不会有刚刚写入的那条消息的信息,消费者也就永远读不到那条数据,这种配置保证了可用性,因为性能要好很多,但损失了数据一致性;
    配置:
    replication.factor = 3
    min.insync.replica = 3
    acks = 1

  - 还有一种配置是公认比较推荐的一种配置,基于这种配置,使得kafka在一致性和可用性之间达到了一种平衡状态,因为在这种配置下,可以容忍主节点宕机的情况下,仍然保证数据强一致性和整体可用性,
    但是如果有两个节点宕机,就整体不可用了
    配置:
    replication.factor = 3
    min.insync.replica = 2
    acks = all
 　
  来解释一下这三条配置的意义
  - replication.factor = 3
    这个配置项指定了每个分区的副本数量,在这个例子中,每个分区都会有三个副本;设置副本数为3可以确保即使一个Broker失效,系统仍然可以正常继续运行,因为仍有两个副本可用

  - min.insync.replicas = 3
    这个配置指定了在写入消息时,需要保持同步的最小副本数量,在这个例子中,写入操作需要确保至少三个副本都同步写入成功,才会认为本次写入成功;这个配置有助于确保在某些副本
    不可用的情况下,仍然保证消息的可靠性

  - acks = all
    这个配置确定了生产者收到确认的条件,在这个例子中,表示只有所有ISR都确认收到消息后,才会认为消息已经成功写入;
  
    需要注意,如果min.insync.replica和acks两个参数都配置了,在某些特定情况下,只有其中一个参数的要求得到满足,那么就可以认为是写入操作成功,换句话说,这两个参数的要求可以互相补充的;