# 简述kafka基础架构
  - Producer: 消息生产者,就是向kafka broker发消息的客户端
  - Consumer: 消息消费者,就是从kafka broker取消息的客户端
  - Consumer Group:
    消费者组,由多个consumer组成,消费者组内每个消费者负责消费不同分区的数据,一个分区只能由一个组内消费者消费;消费者组之间互不影响;所有消费者都属于某个消费者组,即消费者组是
  逻辑上的一个订阅者;(这里解释一下,假设我们有一个topic有三个partition,然后我们有三个消费者组,且每组内有三个消费者,那此时,第一个消费者组里的三个消费者具体消费的partition
  是固定的,即一个分区只能由一个组内消费者消费)
  - Broker: 一台kafka服务器就是一个broker,一个集群由多个broker组成,一个broker容纳多个topic
  - Topic: 可以理解为是对消息的分类,每一次生产和消费消息都要指明topic;
  - Partition: 
    为了实现扩展性,一个非常大的topic可以分布到多个broker上,一个topic可以分为多个partition,每个partition是一个有序的队列,每个partition在存储层面是
  append log文件,任何发布到此partition的消息都会被直接追加到log文件尾部;
    之所以要分区,就是因为kafka基于文件进行存储,当文件内容大到一定程度时,很容易达到单个磁盘的上限,因此采用分区的办法,一个分区对应一个文件,这样就可以将数据分别存储到不同的server上去,
  这样做也可以负载均衡,容纳更多的消费者;
  - Replica: 副本,为了保证集群中的某个节点发生故障时,该节点上的partition数据不丢失,且kafka仍然能够继续工作,kafka提供了副本机制,一个topic的每个分区都有若干个副本,即一个leader分区
  和若干个follower副本,需要注意,数据操作只会在leader分区上进行,follower副本只是用于备份和故障恢复;
  - Offset: 消息在文件中的位置就称为offset即偏移量,offset是一个long型数字,它可以唯一标记一条消息,由于kafka并没有提供其他额外的索引机制来存储offset,文件只能顺序的读写;