# 如何避免kafka中的消息重复消费
  首先,kafka的broker上存储的消息都有一个offset的标记,然后kafka的消费者是通过offset这个标记来维护当前已经消费的数据的,消费者每消费一批数据,
kafka就会更新offset的值,以此来避免重复消费;默认情况下,消息消费完成以后,会自动提交offset,kafka消费端自动提交的逻辑里有一个默认5秒的间隔,也就
是说在5秒之后下一次向Broker获取消息的时候来实现offset的提交,所以在consumer消费过程中,应用程序强制被kill或宕机时,可能会导致offset没有提交,
从而产生重复消费的问题;
  还有一种情况也会出现重复消费,在kafka中存在Partition Balance的一个机制,就是把多个partition均匀的分配给多个消费者,那么consumer端会从分配
的partition里面去消费消息,如果consumer在默认的5分钟以内没办法处理完这一批消息,就会触发kafka的Rebalance机制,从而导致offset自动提交失败,而
在重新rebalance以后,consumer端还是会从之前没有提交的offset位置开始去消费,从而导致重复消费的一个问题;
　
  如何解决?
  - 提高消费端的处理能力来避免触发rebalance,
    比如采取异步的方式来处理消息,缩短单个消息的消费时长或调整消费端消息处理的一个超时时间,也可以减少一次性从Broker上拉取数据的条数
  - 确保幂等性,针对每条消息生成一个md5值,然后保存在数据库或redis之中,在处理消息之前先去mysql或redis中判断,是否已经存在相同的消息的md5,
  如果存在就不需要再消费了(幂等性思想)
  - 对于关键应用,通过手动ack确认的机制来确保消息消费成功后才ack;
  - 检查点和日志,使用外部的持久化存储来记录消息处理的状态,确保消息的处理进度可以恢复